{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class MultiOutputPerceptron:\n",
        "    def __init__(self, input_size, output_size=7, learning_rate=0.01, n_iters=1000):\n",
        "        self.lr = learning_rate\n",
        "        self.n_iters = n_iters\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.weights = np.zeros((output_size, input_size))  # shape: (7, 5)\n",
        "        self.biases = np.zeros(output_size)\n",
        "        self.errors_per_epoch = []\n",
        "\n",
        "    def activation(self, y_in):\n",
        "        # Bipolar step activation function\n",
        "        return np.where(y_in > 0, 1, np.where(y_in < 0, -1, 0))\n",
        "\n",
        "    def fit(self, X, T):  # T: target output vectors\n",
        "        for epoch in range(self.n_iters):\n",
        "            total_error = 0\n",
        "            for xi, target in zip(X, T):\n",
        "                for j in range(self.output_size):\n",
        "                    y_in = np.dot(self.weights[j], xi) + self.biases[j]\n",
        "                    y = self.activation(y_in)\n",
        "                    if y != target[j]:\n",
        "                        # Update weights and bias\n",
        "                        self.biases[j] += self.lr * target[j]\n",
        "                        self.weights[j] += self.lr * target[j] * xi\n",
        "                        total_error += 1\n",
        "            self.errors_per_epoch.append(total_error)\n",
        "\n",
        "    def predict(self, X):\n",
        "        outputs = []\n",
        "        for xi in X:\n",
        "            y_pred = []\n",
        "            for j in range(self.output_size):\n",
        "                y_in = np.dot(self.weights[j], xi) + self.biases[j]\n",
        "                y = self.activation(y_in)\n",
        "                y_pred.append(y)\n",
        "            outputs.append(y_pred)\n",
        "        return np.array(outputs)\n",
        "def get_grade(total_marks):\n",
        "    grade_boundaries = {\n",
        "        'S': (90, 100),\n",
        "        'A': (80, 89),\n",
        "        'B': (70, 79),\n",
        "        'C': (60, 69),\n",
        "        'D': (50, 59),\n",
        "        'E': (40, 49),\n",
        "        'F': (0, 39),\n",
        "    }\n",
        "    for grade, (low, high) in grade_boundaries.items():\n",
        "        if low <= total_marks <= high:\n",
        "            return grade\n",
        "    return 'F'  # Default fallback\n",
        "\n",
        "def grade_to_vector(grade):\n",
        "    grade_map = {\n",
        "        'S': [1, 1, 1, 1, 1, 1, 1],\n",
        "        'A': [-1, 1, 1, 1, 1, 1, 1],\n",
        "        'B': [-1, -1, 1, 1, 1, 1, 1],\n",
        "        'C': [-1, -1, -1, 1, 1, 1, 1],\n",
        "        'D': [-1, -1, -1, -1, 1, 1, 1],\n",
        "        'E': [-1, -1, -1, -1, -1, 1, 1],\n",
        "        'F': [-1, -1, -1, -1, -1, -1, 1],\n",
        "    }\n",
        "    return grade_map[grade]\n",
        "def generate_data(n_samples=1000, seed=42):\n",
        "    np.random.seed(seed)\n",
        "    X = np.random.randint(0, 101, size=(n_samples, 5))  # 5 subject marks\n",
        "    T = []\n",
        "    for marks in X:\n",
        "        avg = np.mean(marks)\n",
        "        grade = get_grade(avg)\n",
        "        T.append(grade_to_vector(grade))\n",
        "    return X, np.array(T)\n",
        "if __name__ == '__main__':\n",
        "    # Generate training data\n",
        "    X_train, T_train = generate_data(n_samples=1000)\n",
        "\n",
        "    # Train multi-output perceptron\n",
        "    model = MultiOutputPerceptron(input_size=5, output_size=7, learning_rate=0.01, n_iters=100)\n",
        "    model.fit(X_train, T_train)\n",
        "\n",
        "    # Test on 2000 random samples\n",
        "    X_test, T_test = generate_data(n_samples=2000, seed=99)\n",
        "    predictions = model.predict(X_test)\n",
        "\n",
        "    # Count mismatches\n",
        "    mismatches = np.sum(~np.all(predictions == T_test, axis=1))\n",
        "    print(f\"\\nWrong Predictions: {mismatches} out of 2000\")"
      ],
      "metadata": {
        "id": "FIdPP1J1s_eE",
        "outputId": "49fe5412-d036-4ed4-8c6e-889c77c18dff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "FIdPP1J1s_eE",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Wrong Predictions: 1611 out of 2000\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}